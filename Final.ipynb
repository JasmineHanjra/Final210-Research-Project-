{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf6d44f-72a6-4b23-94f1-1709c078885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    # Load dataset\n",
    "    print(\"Loading dataset...\")\n",
    "    spotify_data = pd.read_csv('spotify_tracks.csv')\n",
    "    print(spotify_data.head())\n",
    "    print(spotify_data.info())\n",
    "\n",
    "    # Handle missing values\n",
    "    print(\"Handling missing values...\")\n",
    "    spotify_data.dropna(inplace=True)\n",
    "\n",
    "    # Convert duration_ms to minutes\n",
    "    print(\"Converting duration_ms to duration_min...\")\n",
    "    spotify_data['duration_min'] = spotify_data['duration_ms'] / 60000.0\n",
    "\n",
    "    # Correlation heatmap for numeric features\n",
    "    print(\"Plotting correlation heatmap...\")\n",
    "    numeric_columns = ['popularity', 'duration_min']\n",
    "    correlation_matrix = spotify_data[numeric_columns].corr()\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "    plt.title('Correlation Heatmap')\n",
    "    plt.show()\n",
    "\n",
    "    # Different Genre Analysis\n",
    "    print(\"Analyzing genres...\")\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.boxplot(x='genre', y='popularity', data=spotify_data)\n",
    "    plt.title('Genre vs. Popularity')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "    # Explicit Content Analysis\n",
    "    print(\"Analyzing explicit content...\")\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.barplot(x='explicit', y='popularity', data=spotify_data)\n",
    "    plt.title('Explicit Content vs. Popularity')\n",
    "    plt.xlabel('Explicit')\n",
    "    plt.ylabel('Popularity')\n",
    "    plt.show()\n",
    "\n",
    "    # Artist-specific Analysis: Top 10 artists by average popularity\n",
    "    print(\"Analyzing top artists...\")\n",
    "    top_artists = spotify_data.groupby('artists')['popularity'].mean().sort_values(ascending=False).head(10)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    top_artists.plot(kind='bar', color='skyblue')\n",
    "    plt.title('Top 10 Artists by Average Popularity')\n",
    "    plt.xlabel('Artist')\n",
    "    plt.ylabel('Average Popularity')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Album Analysis: Top 10 albums by average popularity\n",
    "    print(\"Analyzing top albums...\")\n",
    "    top_albums = spotify_data.groupby('album')['popularity'].mean().sort_values(ascending=False).head(10)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    top_albums.plot(kind='bar', color='lightgreen')\n",
    "    plt.title('Top 10 Albums by Average Popularity')\n",
    "    plt.xlabel('Album')\n",
    "    plt.ylabel('Average Popularity')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Outlier detection and handling (using IQR method)\n",
    "    print(\"Handling outliers...\")\n",
    "    Q1 = spotify_data['popularity'].quantile(0.25)\n",
    "    Q3 = spotify_data['popularity'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    spotify_data = spotify_data[(spotify_data['popularity'] >= lower_bound) & (spotify_data['popularity'] <= upper_bound)]\n",
    "\n",
    "    # Distribution plots\n",
    "    print(\"Plotting distribution of popularity...\")\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(spotify_data['popularity'], bins=30, kde=True)\n",
    "    plt.title('Distribution of Song Popularity')\n",
    "    plt.show()\n",
    "\n",
    "    # Pair plot for feature relationships\n",
    "    print(\"Plotting pair plot...\")\n",
    "    sns.pairplot(spotify_data[['popularity', 'duration_min']])\n",
    "    plt.show()\n",
    "\n",
    "    # Encode categorical variables\n",
    "    print(\"Encoding categorical variables...\")\n",
    "    spotify_data_encoded = pd.get_dummies(spotify_data, columns=['genre'], drop_first=True)\n",
    "\n",
    "    # Features and target variable\n",
    "    print(\"Defining features and target variable...\")\n",
    "    features = ['duration_min'] + list(spotify_data_encoded.columns[spotify_data_encoded.columns.str.startswith('genre_')])\n",
    "    X = spotify_data_encoded[features]\n",
    "    y = spotify_data_encoded['popularity']\n",
    "\n",
    "    # Train-test split\n",
    "    print(\"Splitting data into train and test sets...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Linear Regression Model\n",
    "    print(\"Training Linear Regression model...\")\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    print(\"Making predictions...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate model performance\n",
    "    print(\"Evaluating model performance...\")\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f'Mean Squared Error (Linear Regression): {mse}')\n",
    "\n",
    "    # Predicted vs actual values plot\n",
    "    print(\"Plotting predicted vs actual values...\")\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_test, y_pred, color='blue')\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--', color='red')\n",
    "    plt.title('Linear Regression: Predicted vs Actual Popularity')\n",
    "    plt.xlabel('Actual Popularity')\n",
    "    plt.ylabel('Predicted Popularity')\n",
    "    plt.show()\n",
    "\n",
    "    # Coefficients\n",
    "    print(\"Printing coefficients...\")\n",
    "    print('Coefficients:')\n",
    "    for feature, coef in zip(features, model.coef_):\n",
    "        print(f'{feature}: {coef}')\n",
    "\n",
    "    feature_names = X.columns\n",
    "    coefficients = model.coef_\n",
    "\n",
    "    # Plotting feature importances\n",
    "    print(\"Plotting feature importances...\")\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.bar(feature_names, coefficients, color='skyblue')\n",
    "    plt.xlabel('Feature')\n",
    "    plt.ylabel('Coefficient')\n",
    "    plt.title('Feature Importances in Linear Regression Model')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "    # Residual Analysis\n",
    "    print(\"Performing residual analysis...\")\n",
    "    residuals = y_test - y_pred\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_pred, residuals, color='blue')\n",
    "    plt.title('Residual Analysis')\n",
    "    plt.xlabel('Predicted Popularity')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.axhline(y=0, color='red', linestyle='--')\n",
    "    plt.show()\n",
    "\n",
    "    # Model Comparison\n",
    "    print(\"Comparing models...\")\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Random Forest': RandomForestRegressor(random_state=42),\n",
    "        'Gradient Boosting': GradientBoostingRegressor(random_state=42)\n",
    "    }\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"Training {name} model...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        print(f'{name} - MSE: {mse}, MAE: {mae}, R2: {r2}')\n",
    "\n",
    "   # Define the parameter grid for Random Forest\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "\n",
    "    # Perform GridSearchCV with cross-validation\n",
    "    grid_search = GridSearchCV(estimator=RandomForestRegressor(random_state=42),\n",
    "                            param_grid=param_grid,\n",
    "                            cv=5,\n",
    "                            scoring='neg_mean_squared_error',\n",
    "                            verbose=0,  # Increase verbosity to see progress\n",
    "                            n_jobs=-1)  # Use all available CPU cores\n",
    "\n",
    "    # Fit the grid search to find the best model\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Retrieve the best model found by GridSearchCV\n",
    "    best_rf = grid_search.best_estimator_\n",
    "\n",
    "    # Evaluate the best model on the test set\n",
    "    y_pred_best_rf = best_rf.predict(X_test)\n",
    "    mse_best_rf = mean_squared_error(y_test, y_pred_best_rf)\n",
    "    print(f'Best Random Forest - MSE: {mse_best_rf}')\n",
    "\n",
    "    # Print the best parameters found by GridSearchCV\n",
    "    print(f'Best parameters: {grid_search.best_params_}')\n",
    "\n",
    "    # plot feature importances for the best Random Forest model\n",
    "    importances = best_rf.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.title('Feature Importances')\n",
    "    plt.bar(range(X.shape[1]), importances[indices], color='r', align='center')\n",
    "    plt.xticks(range(X.shape[1]), [features[i] for i in indices], rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "    # perform residual analysis for the best Random Forest model\n",
    "    residuals_best_rf = y_test - y_pred_best_rf\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_pred_best_rf, residuals_best_rf, color='blue')\n",
    "    plt.title('Residual Analysis (Random Forest)')\n",
    "    plt.xlabel('Predicted Popularity')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.axhline(y=0, color='red', linestyle='--')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # Scaling numerical features for model improvement\n",
    "    print(\"Scaling numerical features...\")\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = X.copy()\n",
    "    X_scaled['duration_min'] = scaler.fit_transform(X_scaled[['duration_min']])\n",
    "\n",
    "    # Training and test sets for scaled data\n",
    "    print(\"Splitting scaled data into train and test sets...\")\n",
    "    X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize and fit the model with scaled data\n",
    "    print(\"Training Linear Regression model with scaled data...\")\n",
    "    model_scaled = LinearRegression()\n",
    "    model_scaled.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "    y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
    "    mse_scaled = mean_squared_error(y_test_scaled, y_pred_scaled)\n",
    "    print(f'Mean Squared Error (Scaled Linear Regression): {mse_scaled}')\n",
    "\n",
    "    # Function to predict popularity\n",
    "    def predict_popularity(duration_min, genre, spotify_data, model):\n",
    "        spotify_data_encoded = pd.get_dummies(spotify_data, columns=['genre'], drop_first=True)\n",
    "        genre_columns = [col for col in spotify_data_encoded.columns if col.startswith('genre_')]\n",
    "        new_sample_data = {'duration_min': [duration_min]}\n",
    "        for genre_col in genre_columns:\n",
    "            new_sample_data[genre_col] = [1 if genre_col == f'genre_{genre}' else 0]\n",
    "        \n",
    "        new_sample = pd.DataFrame(new_sample_data)\n",
    "        new_sample['duration_min'] = scaler.transform(new_sample[['duration_min']])\n",
    "        predicted_popularity = model.predict(new_sample)[0]\n",
    "        return predicted_popularity\n",
    "\n",
    "    # Example usage\n",
    "    print(\"Predicting popularity for example input...\")\n",
    "    predicted_popularity = predict_popularity(3.5, 'Pop', spotify_data, model_scaled)\n",
    "    print(f'Predicted Popularity: {predicted_popularity}')\n",
    "\n",
    "    print(\"Script executed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0009d04-8bff-4e71-b13e-87b4e8f0e04a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
